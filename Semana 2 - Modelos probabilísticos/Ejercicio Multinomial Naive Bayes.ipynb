{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modelos probabilísticos (Ejercicio)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Aplicación de Naive Bayes multinomial a la detección de SMS *spam*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En este ejercicio se pide reproducir lo realizado en el caso práctico que se ha descrito en los vídeos (análisis de sentimiento en críticas de cine), pero ahora para detectar cuándo un mensaje corto (SMS) es *spam*."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### El conjunto de datos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El conjunto de datos consiste una serie de mensajes SMS (5574 en total), que están clasificados como mensajes basura (*spam*) o mensajes normales (*ham*). Los datos se pueden obtener en el [UCI Machine Learning Repository](https://archive.ics.uci.edu/ml/datasets/sms+spam+collection). \n",
    "\n",
    "En concreto, descargar el fichero [smsspamcollection.zip](https://archive.ics.uci.edu/ml/machine-learning-databases/00228/smsspamcollection.zip), y descomprimirlo para obtener un fichero de texto SMSSpamCollection. En este fichero de texto hay una línea por cada sms, con el formato: *clase* *tabulador* *sms*. Por ejemplo, la primera línea es:\n",
    "\n",
    "`ham\tGo until jurong point, crazy.. Available only in bugis n great world la e buffet... Cine there got amore wat...`\n",
    "\n",
    "El fichero debe ser leído convenientemente para poder aplicar la vectorización. Se puede hacer la lectura usando las funciones python de lectura de ficheros, pero se recomienda usar la instrucción `read_table` de la biblioteca `pandas`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Pandas* es una biblioteca de python muy utilizada para manipular y analizar datos. Si el fichero se lee con la orden `read_table` (se pide averiguar la manera concreta de hacerlo), entonces se obtendrá una tabla (o *Data Frame*), en el que las etiquetas serán una columna y los correspondientes sms otra. Esto permite obtener de manera sencilla la lista de etiquetas o clases, y por otro lado la lista de mensajes, en el mismo orden.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Aprendiendo a clasificar SMSs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se pide reproducir con estos datos lo realizado en el *notebook* en el que se aplica Naive Bayes Multinomial al análisis de sentimientos de críticas de cine, pero ahora para clasificar un SMS como *spam* o como normal. Esto incluye:\n",
    "\n",
    "* Separación de los textos en entrenamiento y prueba \n",
    "* Vectorización de los textos \n",
    "* Aprendizaje con `MultinomialNB`\n",
    "* Mostrar algunas clasificaciones sobre sms concretos.\n",
    "* Rendimiento sobre entrenamiento y prueba.\n",
    "* Ajuste manual del parámetro de suavizado\n",
    "* Vectorización con `min_df` y `stop_words` \n",
    "\n",
    "**Nota**: este conjunto de datos no es balanceado (la mayoría son *ham*). Por tanto, usar `score` no es muy ilustrativo del rendimiento, ya que un clasificador \"tonto\" que siempre predijera *ham* tendría un rendimiento alto. Por ello, en este caso también se hace necesario usar el método `confusion_matrix` del módulo `metrics`. Se pide también explicar la salida que proporciona dicha métrica.\n",
    "\n",
    "Se pide **comentar adecuadamente cada paso realizado**, relacionándolo con lo visto en la teoría. En particular, se pide mostrar parte de los atributos `class_count_`, `class_log_prior_`, `feature_count_` y `feature_log_prob_`, explicando claramente qué son cada uno de ellos. Explicar también cómo realiza las predicciones el modelo aprendido, tal y como se ha explicado en la teoría.  \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      tag                                               text\n",
      "0       1  Go until jurong point, crazy.. Available only ...\n",
      "1       1                      Ok lar... Joking wif u oni...\n",
      "2       0  Free entry in 2 a wkly comp to win FA Cup fina...\n",
      "3       1  U dun say so early hor... U c already then say...\n",
      "4       1  Nah I don't think he goes to usf, he lives aro...\n",
      "...   ...                                                ...\n",
      "5567    0  This is the 2nd time we have tried 2 contact u...\n",
      "5568    1               Will ü b going to esplanade fr home?\n",
      "5569    1  Pity, * was in mood for that. So...any other s...\n",
      "5570    1  The guy did some bitching but I acted like i'd...\n",
      "5571    1                         Rofl. Its true to its name\n",
      "\n",
      "[5572 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "# Pandas\n",
    "convertTag = lambda x: 1 if x == 'ham' else 0\n",
    "collection = pd.read_table('smsspamcollection/SMSSpamCollection', header=None, names = ['tag','text'], converters={'tag': convertTag } )\n",
    "target_names = ['spam', 'ham']\n",
    "print(collection)\n",
    "# ¿quitar los '...'?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ejemplos por cada clase: [ 747 4825]\n"
     ]
    }
   ],
   "source": [
    "# Separacion de los textos en entrenamiento y prueba\n",
    "messages = collection.text.tolist()\n",
    "tags = collection.tag.tolist() #y_train\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "text_train, text_test, y_train, y_test = train_test_split(messages, tags, stratify = tags, test_size = 0.2)\n",
    "\n",
    "import numpy as np\n",
    "print(\"Ejemplos por cada clase: {}\".format(np.bincount(tags)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'list'>\n",
      "X_train:\n",
      "<4457x8713 sparse matrix of type '<class 'numpy.int64'>'\n",
      "\twith 59354 stored elements in Compressed Sparse Row format>\n",
      "X_test:\n",
      "<1115x8713 sparse matrix of type '<class 'numpy.int64'>'\n",
      "\twith 14815 stored elements in Compressed Sparse Row format>\n"
     ]
    }
   ],
   "source": [
    "# Vectorizacion de los textos\n",
    "print(type(text_train))\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "vect = CountVectorizer().fit(messages)\n",
    "# print(\"Tamaño del vocabulario: {}\".format(len(vect.vocabulary_)))\n",
    "# print(\"Vocabulario:\\n {}\".format(vect.vocabulary_))\n",
    "\n",
    "X_train = vect.transform(text_train)\n",
    "#print(\"X_train:\\n{}\".format(repr(X_train)))\n",
    "X_test = vect.transform(text_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aprendizaje con `MultinomialNB`\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "multinb=MultinomialNB().fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 598. 3859.]\n",
      "[-2.00864042 -0.14406781]\n",
      "[[ 9. 22.  0. ...  0.  1.  0.]\n",
      " [ 0.  0.  0. ...  1.  0.  1.]]\n",
      "[[ -7.73048231  -6.89757318 -10.0330674  ... -10.0330674   -9.33992022\n",
      "  -10.0330674 ]\n",
      " [-10.98559776 -10.98559776 -10.98559776 ... -10.29245058 -10.98559776\n",
      "  -10.29245058]]\n"
     ]
    }
   ],
   "source": [
    "print(multinb.class_count_)\n",
    "print(multinb.class_log_prior_)\n",
    "print(multinb.feature_count_)\n",
    "print(multinb.feature_log_prob_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Octavo mensaje del conjunto de test: \n",
      "\n",
      "It took Mr owl 3 licks\n",
      "\n",
      "Clasificación verdadera: 1.\n",
      "\n",
      "\n",
      "Décimo mensaje del conjunto de test: \n",
      "\n",
      "CALL 09090900040 & LISTEN TO EXTREME DIRTY LIVE CHAT GOING ON IN THE OFFICE RIGHT NOW TOTAL PRIVACY NO ONE KNOWS YOUR [sic] LISTENING 60P MIN 24/7MP 0870753331018+\n",
      "\n",
      "Clasificación verdadera: 0\n",
      "Predicción del clasificador para el noveno mensaje: 1\n",
      "\n",
      "Predicción del clasificador para el décimo mensaje: 1\n",
      "Predicción de probabilidad para el noveno mensaje: [0.02587709 0.97412291]\n",
      "\n",
      "Predicción de probabilidad para el décimo mensaje: [0.43332185 0.56667815]\n"
     ]
    }
   ],
   "source": [
    "# Clasificaciones de sms concretos\n",
    "print(\"Octavo mensaje del conjunto de test: \\n\\n{}\\n\".format(text_test[7]))\n",
    "print(\"Clasificación verdadera: {}.\\n\\n\".format(y_test[7]))\n",
    "\n",
    "print(\"Décimo mensaje del conjunto de test: \\n\\n{}\\n\".format(text_test[9]))\n",
    "print(\"Clasificación verdadera: {}\".format(y_test[9]))\n",
    "\n",
    "print(\"Predicción del clasificador para el noveno mensaje: {}\\n\".format(multinb.predict(vect.transform([text_test[7]]))[0]))\n",
    "print(\"Predicción del clasificador para el décimo mensaje: {}\".format(multinb.predict(vect.transform([text_test[9]]))[0]))\n",
    "\n",
    "print(\"Predicción de probabilidad para el noveno mensaje: {}\\n\".format(multinb.predict_proba(vect.transform([text_test[7]]))[0]))\n",
    "print(\"Predicción de probabilidad para el décimo mensaje: {}\".format(multinb.predict_proba(vect.transform([text_test[9]]))[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 577   21]\n",
      " [  10 3849]]\n"
     ]
    }
   ],
   "source": [
    "# Rendimiento sobre entrenamiento y prueba.\n",
    "# https://scikit-learn.org/stable/modules/generated/sklearn.metrics.confusion_matrix.html\n",
    "\n",
    "predictTrain = multinb.predict(X_train)\n",
    "predictTest = multinb.predict(X_test)\n",
    "from sklearn.metrics import confusion_matrix\n",
    "matrixTrain = confusion_matrix(y_train, predictTrain)\n",
    "spamsTrain = matrixTrain[0][0]/matrixTrain[0][0]+matrixTrain[1][0]\n",
    "hamsTrain = matrixTrain[1][1]/matrixTrain[1][1]+matrixTrain[0][1]\n",
    "print(matrixTrain)\n",
    "matrixTest = confusion_matrix(y_test, predictTest)\n",
    "spamsTest = matrixTest[0][0]/matrixTest[0][0]+matrixTest[1][0]\n",
    "hamsTest = matrixTest[1][1]/matrixTest[1][1]+matrixTest[0][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mejor parámetro:  {'alpha': 0.01}\n",
      "Rendimiento de MultonomialNB en validación cruzada, con el mejor parámetro: 0.98\n"
     ]
    }
   ],
   "source": [
    "# Ajuste manual del parámetro de suavizado\n",
    "# Modificar algo, esta copiado y pegado !!!!!!!!!!!!!!!!!!!!!!!!!!\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "param_grid_nb = {'alpha': [0.0001,0.001, 0.01,0.1, 1, 10,100,200]}\n",
    "grid_nb = GridSearchCV(MultinomialNB(), param_grid_nb, cv=5)\n",
    "grid_nb.fit(X_train, y_train)\n",
    "print(\"Mejor parámetro: \", grid_nb.best_params_)\n",
    "print(\"Rendimiento de MultonomialNB en validación cruzada, con el mejor parámetro: {:.2f}\".format(grid_nb.best_score_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Número de términos en el vocabulario original: 8713\n",
      "Número de términos en el vocabulario con stop words y min_df: 50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.9/site-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function get_feature_names is deprecated; get_feature_names is deprecated in 1.0 and will be removed in 1.2. Please use get_feature_names_out instead.\n",
      "  warnings.warn(msg, category=FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "# Vectorización con `min_df` y `stop_words`\n",
    "# Modificar algo, esta copiado y pegado !!!!!!!!!!!!!!!!!!!!!!!!!!\n",
    "vect2 = CountVectorizer(min_df=80, stop_words=\"english\").fit(text_train)\n",
    "X2_train = vect2.transform(text_train)\n",
    "print(\"Número de términos en el vocabulario original: {}\".format(len(vect.get_feature_names())))\n",
    "feature_names2 = vect2.get_feature_names()\n",
    "print(\"Número de términos en el vocabulario con stop words y min_df: {}\".format(len(feature_names2)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
