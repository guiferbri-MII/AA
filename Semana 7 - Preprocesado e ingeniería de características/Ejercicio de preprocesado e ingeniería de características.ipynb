{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocesado e ingeniería de características"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Procesado de los datos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El conjunto de datos sobre reconocimiento de vinos está incluido en *Scikit-learn*, se obtiene usando la función `load_wine` incluida en la librería `sklearn.datasets`. Este conjunto de datos contiene 178 ejemplos de distintas variedades de vino, con 13 características y tres clasificaciones posibles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_wine\n",
    "\n",
    "wine = load_wine()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Este conjunto de datos es un diccionario con varios campos:\n",
    "* `data`: Es el conjunto de datos, se trata de un array en el que cada componente es un array con las características de cada instancia.\n",
    "* `target`: Es el conjunto de valores de clasificación para cada instancia. Es un array del mismo tamaño que `data`, en el que se indica el valor de clasificación de cada instancia, en el mismo orden en que éstas se encuentran en el array `data`.\n",
    "* `DESCR`: Es una descripción del conjunto de datos.\n",
    "* `target_names`: Es un array con los nombres de cada valor de clasificación.\n",
    "* `feature_names`: Es un array con los nombres de cada característica.\n",
    "\n",
    "Almacenamos los datos en las variables `X_data`, `y_data`, `X_names` e `y_names`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_data, y_data, X_names, y_names = \\\n",
    "    wine.data, wine.target, wine.feature_names, wine.target_names"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Contenido del ejercicio"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El ejercicio consiste en aplicar distintas estrategias de reducción de dimensionalidad y comparar los resultados\n",
    "* Implementar una función para realizar la eliminación recursiva de características tal y como se ha explicado en teoría, para reducir el número de características hasta un valor dado. (No es igual al método implementado por la clase RFE incluido en *Scikit-learn*)\n",
    "* Realizar selección de características basada en modelos para reducir el número de características del conjunto de datos. Investigar los parámetros de la clase SelectFromModel para reducir el número de características hasta un valor dado.\n",
    "* Estudiar las características del conjunto de datos mediante análisis de componentes principales. Reducir el número de características hasta un valor dado.\n",
    "\n",
    "El **desarrollo tiene que estar razonado**, indicando en cada apartado qué se está haciendo, **demostrando así el conocimiento adquirido en este módulo**. ¿Qué conclusiones puedes sacar sobre las características de este conjunto de datos?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ejercicio 1\n",
    "#### Implementar una función para realizar la eliminación recursiva de características tal y como se ha explicado en teoría, para reducir el número de características hasta un valor dado. (No es igual al método implementado por la clase RFE incluido en *Scikit-learn*)\n",
    "\n",
    "Definimos la función *removeFeature* que recibe los siguientes parámetros:\n",
    "- *X_data*: Conjunto de datos\n",
    "- *y_data*: Valores de clasificación\n",
    "- *num_features*: Número de características a eliminar\n",
    "- *X_names_feature*: Nombres de las características\n",
    "- *removedFeaturesList*: Lista con las características que se van eliminando. Inicialmente es una lista vacía para se utilizará al llamar a la función de forma recursiva para almacenar el nombre de las características que se van eliminando.\n",
    "\n",
    "Esta función va eliminando características y comprobando el rendimiento que se obtiene al eliminarla. Finalmente eliminará con la que mejores resultados se consigan. Así hasta eliminar el número de características que se indique en el parámetro *num_features*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import LinearSVC\n",
    "import numpy as np\n",
    "def removeFeature(X_data, y_data, num_features, X_names_feature, removedFeaturesList):\n",
    "    model = LinearSVC(random_state=486, max_iter=10000).fit(X_data, y_data)\n",
    "    bestScore = model.score(X_data,y_data)\n",
    "    bestX_data = np.copy(X_data)\n",
    "    X_features = np.copy(X_names_feature)\n",
    "\n",
    "    removedFeature = ''\n",
    "    for i in range(X_data.shape[1]):\n",
    "        X_data_aux = np.copy(X_data)\n",
    "        X_data_reduced = np.delete(X_data_aux, i, 1)\n",
    "        model = LinearSVC(max_iter=10000).fit(X_data_reduced, y_data)\n",
    "        score = model.score(X_data_reduced, y_data)\n",
    "        if score > bestScore:\n",
    "            bestScore = score\n",
    "            bestX_data = X_data_reduced\n",
    "            removedFeature = X_names_feature[i]\n",
    "            X_names_feature_aux = np.copy(X_names_feature)\n",
    "            X_features = np.delete(X_names_feature_aux, i, 0)\n",
    "\n",
    "    if removedFeature != '':\n",
    "        removedFeaturesList.append(removedFeature)\n",
    "        if len(removedFeaturesList) < num_features:\n",
    "            return removeFeature(bestX_data, y_data, num_features, X_features, removedFeaturesList)\n",
    "        else:\n",
    "            return bestX_data, X_features, removedFeaturesList, bestScore\n",
    "    else:\n",
    "        return bestX_data, X_features, removedFeaturesList, bestScore"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos a utilizar la función que se ha definido para eliminar hasta 2 características y a ver qué resultados obtenemos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.9/site-packages/sklearn/svm/_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.9/site-packages/sklearn/svm/_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.9/site-packages/sklearn/svm/_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.9/site-packages/sklearn/svm/_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.9/site-packages/sklearn/svm/_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.9/site-packages/sklearn/svm/_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.9/site-packages/sklearn/svm/_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.9/site-packages/sklearn/svm/_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.9/site-packages/sklearn/svm/_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.9/site-packages/sklearn/svm/_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.9/site-packages/sklearn/svm/_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.9/site-packages/sklearn/svm/_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.9/site-packages/sklearn/svm/_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.9/site-packages/sklearn/svm/_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.9/site-packages/sklearn/svm/_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.9/site-packages/sklearn/svm/_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.9/site-packages/sklearn/svm/_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.9/site-packages/sklearn/svm/_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.9/site-packages/sklearn/svm/_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.9/site-packages/sklearn/svm/_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.9/site-packages/sklearn/svm/_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.9/site-packages/sklearn/svm/_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.9/site-packages/sklearn/svm/_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.9/site-packages/sklearn/svm/_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Se han eliminado las siguientes 2 características: ['nonflavanoid_phenols', 'alcohol']\n",
      "Rendimiento obtenido al eliminar las características: 0.966\n",
      "Forma del dataset resultante:  (178, 11)\n",
      "Características finales:  ['malic_acid' 'ash' 'alcalinity_of_ash' 'magnesium' 'total_phenols'\n",
      " 'flavanoids' 'proanthocyanins' 'color_intensity' 'hue'\n",
      " 'od280/od315_of_diluted_wines' 'proline']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.9/site-packages/sklearn/svm/_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.9/site-packages/sklearn/svm/_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.9/site-packages/sklearn/svm/_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "X_data_result, X_names_result, removedFeatures_result, bestScore = removeFeature(X_data, y_data, 2, X_names, [])\n",
    "print('Se han eliminado las siguientes {} características: {}'.format(len(removedFeatures_result), removedFeatures_result))\n",
    "print('Rendimiento obtenido al eliminar las características: {:.3f}'.format(bestScore))\n",
    "print('Forma del dataset resultante: ', X_data_result.shape)\n",
    "print('Características finales: ', X_names_result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ejercicio 2\n",
    "#### Realizar selección de características basada en modelos para reducir el número de características del conjunto de datos. Investigar los parámetros de la clase SelectFromModel para reducir el número de características hasta un valor dado.\n",
    "\n",
    "Entre los distintos parámetros que se pueden utilizar en la clase `SelectFromModel`, vamos a utilizar *max_features* para indicar el máximo número de características a seleccionar.<br>Primero vamos a probar indicando como máximo 11 características y luego como máximo 4. Vamos a seleccionarlas en ambos casos a partir de un modelo lineal con regularización L1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Forma del conjunto inicial es: (178, 13)\n",
      "Rendimiento del conjunto inicial: 0.904\n",
      "Forma del conjunto indicando como máximo 11 características: (178, 5)\n",
      "Rendimiento del conjunto indicando como máximo 11 características: 0.904\n",
      "Forma del conjunto indicando como máximo 4 características: (178, 4)\n",
      "Rendimiento del conjunto indicando como máximo 4 características: 0.865\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_selection import SelectFromModel\n",
    "linear_svm = LinearSVC(C=0.01, penalty=\"l1\", dual=False)\n",
    "score = linear_svm.fit(X_data,y_data).score(X_data,y_data)\n",
    "\n",
    "select = SelectFromModel(linear_svm, max_features = 11)\n",
    "select.fit(X_data,y_data)\n",
    "X_data_11 = select.transform(X_data)\n",
    "score_11 = linear_svm.fit(X_data_11,y_data).score(X_data_11,y_data)\n",
    "\n",
    "select_4 = SelectFromModel(LinearSVC(C=0.01, penalty=\"l1\", dual=False), max_features = 4)\n",
    "select_4.fit(X_data,y_data)\n",
    "X_data_4 = select_4.transform(X_data)\n",
    "score_4 = linear_svm.fit(X_data_4,y_data).score(X_data_4,y_data)\n",
    "\n",
    "print('Forma del conjunto inicial es: {}'.format(X_data.shape))\n",
    "print('Rendimiento del conjunto inicial: {:.3f}'.format(score))\n",
    "print('Forma del conjunto indicando como máximo 11 características: {}'.format(X_data_11.shape))\n",
    "print('Rendimiento del conjunto indicando como máximo 11 características: {:.3f}'.format(score_11))\n",
    "print('Forma del conjunto indicando como máximo 4 características: {}'.format(X_data_4.shape))\n",
    "print('Rendimiento del conjunto indicando como máximo 4 características: {:.3f}'.format(score_4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos ver que aunque indiquemos que como máximo son 11 características, ha seleccionado 5 y obtenemos el mismo rendimiento que con el conjunto inicial que tiene 13 características. En cambio, al obligarle que como máximo tenga 4, obtenemos un conjunto con ese máximo y con una disminución en el rendimiento."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ejercicio 3\n",
    "#### Estudiar las características del conjunto de datos mediante análisis de componentes principales. Reducir el número de características hasta un valor dado.\n",
    "En este ejercicio vamos a aplicar el análisis de componentes principales. En primer lugar los vamos a aplicar al conjunto de datos con todas las características y así ver el grado de importancia de las componentes (autovalores asociados a las componentes principales)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([9.92017895e+04, 1.72535266e+02, 9.43811370e+00, 4.99117861e+00,\n",
       "       1.22884523e+00, 8.41063869e-01, 2.78973523e-01, 1.51381266e-01,\n",
       "       1.12096765e-01, 7.17026032e-02, 3.75759789e-02, 2.10723661e-02,\n",
       "       8.20370314e-03])"
      ]
     },
     "execution_count": 167,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "pca = PCA(n_components=13)\n",
    "pca.fit(X_data)\n",
    "X_pca = pca.transform(X_data)\n",
    "pca.explained_variance_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Observamos que las componentes con mas importancia son las 2 primeras. Siguiendo el ejemplo anterior, vamos a aplicar este análisis primero eliminando 2 características, luego eliminando 9 y finalmente dejando una única característica. Para cada caso vamos a el rendimiento que obtenemos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rendimiento del conjunto inicial: 0.904\n",
      "Rendimiento del conjunto eliminando 2 características: 0.910\n",
      "Rendimiento del conjunto eliminando 9 características: 0.910\n",
      "Rendimiento del conjunto eliminando 12 características: 0.685\n"
     ]
    }
   ],
   "source": [
    "linear_svm = LinearSVC(C=0.01, penalty=\"l1\", dual=False)\n",
    "pca_11 = PCA(n_components=11)\n",
    "pca_11.fit(X_data)\n",
    "X_pca_11 = pca_11.transform(X_data)\n",
    "score_11 = linear_svm.fit(X_pca_11,y_data).score(X_pca_11,y_data)\n",
    "\n",
    "pca_4 = PCA(n_components=4)\n",
    "pca_4.fit(X_data)\n",
    "X_pca_4 = pca_4.transform(X_data)\n",
    "score_4 = linear_svm.fit(X_pca_4,y_data).score(X_pca_4,y_data)\n",
    "\n",
    "pca_1 = PCA(n_components=1)\n",
    "pca_1.fit(X_data)\n",
    "X_pca_1 = pca_1.transform(X_data)\n",
    "score_1 = linear_svm.fit(X_pca_1,y_data).score(X_pca_1,y_data)\n",
    "\n",
    "score = linear_svm.fit(X_data,y_data).score(X_data,y_data)\n",
    "print('Rendimiento del conjunto inicial: {:.3f}'.format(score))\n",
    "print('Rendimiento del conjunto eliminando 2 características: {:.3f}'.format(score_11))\n",
    "print('Rendimiento del conjunto eliminando 9 características: {:.3f}'.format(score_4))\n",
    "print('Rendimiento del conjunto eliminando 12 características: {:.3f}'.format(score_1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vemos que eliminando características mejora levemente el rendimiento, aunque no hay diferencia entre eliminar 9 o 2 características. En cambio, si solo dejamos una única carecterística, el rendimiento empeora notablemente.<br><br>\n",
    "\n",
    "Como conclusión, viendo los resultados obtenidos tras aplicar distintas técnicas para reducir la dimensionalidad, hemos comprobado que este conjunto de datos tiene bastantes características que no aportan mucho y que podemos eliminar, para de esta forma obtener mejores resultados pero con un problema más sencillo, pues se ha reducido la dimensionalidad."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
