{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modelos lineales (ejercicio)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Importante: comentar adecuadamente cada paso realizado**, relacionándolo con lo visto en la teoría."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parte 1: aplicación de modelos lineales a análisis de sentimientos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se pide aplicar algunos de los clasificadores lineales vistos al problema de decidir si una crítica de cine es positiva o negativa. Para ello volvemos a usar los datos de IMDB (Internet Movie Database) que vimos en el módulo 2 (modelo probabilístico).\n",
    "\n",
    "Los datos están disponibles en http://ai.stanford.edu/~amaas/data/sentiment/\n",
    "\n",
    "Vectorizar los textos exactamente como se hizo en la sesión de trabajo del módulo 2, **con *stop_words* y *min_df=100***. \n",
    "\n",
    "Una vez los datos (entrenamiento y prueba) estén vectorizados, aplicar los siguientes clasificadores de scikit learn y medir el rendimiento obtenido:\n",
    "\n",
    "* `LogisticRegression`\n",
    "* `LinearSVC`\n",
    "\n",
    "Probar en cada caso con distintos valores del parámetro `C` de regularización, para obtener el mejor rendimiento sobre el conjunto de test. Explicar claramente el efecto que tiene variar ese parámetro en un sentido o en otro. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ejercicio\n",
    "Lo primero que vamos a realizar, es leer y vectorizar los datos de IMDB siguiendo los pasos que vimos en el módulo 2. Vamos a utilizar el vectorizador aplicando *stop_words* y *min_df* para ganar eficiencia, y a continuación transformar en vectores tanto el conjunto de entrenamiento como el de pruebas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_files\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "reviews_train = load_files(\"data/aclImdb/train/\")\n",
    "reviews_test = load_files(\"data/aclImdb/test/\")\n",
    "text_train, y_train = reviews_train.data, reviews_train.target\n",
    "text_train = [doc.replace(b\"<br />\", b\" \") for doc in text_train]\n",
    "text_test, y_test = reviews_test.data, reviews_test.target\n",
    "text_test = [doc.replace(b\"<br />\", b\" \") for doc in text_test]\n",
    "vect = CountVectorizer(min_df=100, stop_words=\"english\").fit(text_train)\n",
    "X_train = vect.transform(text_train)\n",
    "X_test = vect.transform(text_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora que ya está vectorizado, podemos aplicar los clasificadores. Vamos a empezar por el primero `LogisticRegression`, en el cual las predicciones se van a dar como probabilidades de pertenecer a la clase. Vamos a ver el rendimiento que obtenemos sin aplicar ninguna regularización (la que viene por defecto: $L_2$ con $C=1$).<br>\n",
    "*Aclaración: se ha añadio el parámetro max_iter para evitar el warning: ConvergenceWarning: lbfgs failed to converge (status=1): STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rendimiento sobre entrenamiento: 0.935\n",
      "Rendimiento sobre el conjunto de prueba: 0.849\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "logreg = LogisticRegression(max_iter=10000).fit(X_train, y_train)\n",
    "print(\"Rendimiento sobre entrenamiento: {:.3f}\".format(logreg.score(X_train, y_train)))\n",
    "print(\"Rendimiento sobre el conjunto de prueba: {:.3f}\".format(logreg.score(X_test, y_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El rendimiento sobre el conjunto de entrenamiento es bueno, pero sobre el conjunto de prueba sí es más bajo. Vamos a probar ahora a cambiar la regularización (parámetro `C`) para ver si mejoramos los resultados. Teniendo en cuenta cuanto menor sea el valor de la constante `C`, mayor regularización se está aplicando (es el inverso de la cantidad de regularización), vamos a probar en primer lugar con una regularización baja (*`C`=100*) y luego con una regularización mas alta (*`C`=0.01*)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rendimiento sobre entrenamiento: 0.939\n",
      "Rendimiento sobre el conjunto de prueba: 0.835\n",
      "Rendimiento sobre entrenamiento: 0.897\n",
      "Rendimiento sobre el conjunto de prueba: 0.872\n"
     ]
    }
   ],
   "source": [
    "logreg100 = LogisticRegression(max_iter=10000, C=100).fit(X_train, y_train)\n",
    "print(\"Rendimiento sobre entrenamiento: {:.3f}\".format(logreg100.score(X_train, y_train)))\n",
    "print(\"Rendimiento sobre el conjunto de prueba: {:.3f}\".format(logreg100.score(X_test, y_test)))\n",
    "logreg001 = LogisticRegression(max_iter=10000, C=0.01).fit(X_train, y_train)\n",
    "print(\"Rendimiento sobre entrenamiento: {:.3f}\".format(logreg001.score(X_train, y_train)))\n",
    "print(\"Rendimiento sobre el conjunto de prueba: {:.3f}\".format(logreg001.score(X_test, y_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Viendo los resultados, comprobamos que con menos regularización (*`C`=100*) obtenmos el máximo rendimiento sobre el conjunto de entrenamiento, lo que puede significar que se está sobreajustando. En cambio, con mayor regularización (*`C`=0.01*), se obtienen buenos resultados tanto en el conjunto de entrenamiento como en el conjunto de prueba."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora vamos a aplicar el clasificador `LinearSVC`, que busca el hiperplano que separe la clases pero buscando maximizar la separación entre la frontera y el ejemplo de cada clase. Al clasificar, según el signo del resultado, estará en una lado u otro de la frontera de decisión (hiperplano de separación), lo que significa que se clasificará según el lado en el que esté.<br>\n",
    "Como en el experimento anterior, vamos ver el rendimiento que obtenemos sin aplicar ninguna regularización (por defecto: $L_2$ con $C=1$), aplicando una regularización mayor (*`C`=0.01*) y otra menor (*`C`=100*)<br>\n",
    "*Aclaración: se ha añadio el parámetro max_iter para evitar el warning: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rendimiento sobre entrenamiento: 0.934\n",
      "Rendimiento sobre el conjunto de prueba: 0.839\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import LinearSVC\n",
    "linear_svm = LinearSVC(max_iter=20000).fit(X_train, y_train)\n",
    "print(\"Rendimiento sobre entrenamiento: {:.3f}\".format(linear_svm.score(X_train, y_train)))\n",
    "print(\"Rendimiento sobre el conjunto de prueba: {:.3f}\".format(linear_svm.score(X_test, y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rendimiento sobre entrenamiento: 0.927\n",
      "Rendimiento sobre el conjunto de prueba: 0.835\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.9/site-packages/sklearn/svm/_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import LinearSVC\n",
    "linear_svm = LinearSVC(max_iter=20000, C=100).fit(X_train, y_train)\n",
    "print(\"Rendimiento sobre entrenamiento: {:.3f}\".format(linear_svm.score(X_train, y_train)))\n",
    "print(\"Rendimiento sobre el conjunto de prueba: {:.3f}\".format(linear_svm.score(X_test, y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rendimiento sobre entrenamiento: 0.924\n",
      "Rendimiento sobre el conjunto de prueba: 0.866\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import LinearSVC\n",
    "linear_svm = LinearSVC(max_iter=20000, C=0.01).fit(X_train, y_train)\n",
    "print(\"Rendimiento sobre entrenamiento: {:.3f}\".format(linear_svm.score(X_train, y_train)))\n",
    "print(\"Rendimiento sobre el conjunto de prueba: {:.3f}\".format(linear_svm.score(X_test, y_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comparando los 3 resultados, podemos ver que con mayor regularización (*`C`=0.01*) obtenemos mejores resultados sobre el conjunto de prueba; en cambio con la regularización por defecto (*`C`=1*) se obtiene mejor resultado sobre el conjunto de entrenamiento, aunque muy leve la mejora pues la diferencia aplicando mayor regularización (*`C`=0.01*) es de 0.006"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parte 2: modelos lineales para reconocimiento de dígitos escritos a mano\n",
    "\n",
    "\n",
    "La función `load_digits` nos permite cargar una versión reducida de un conjunto de imágenes de dígitos escritos a mano (ver detalles en el manual):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from sklearn.datasets import load_digits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "digits = load_digits()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos incluso visualizar los dígitos. Por ejemplo, este es el primero de ellos (un cero):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 288x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "plt.gray()\n",
    "plt.matshow(digits.images[0]) \n",
    "plt.show() \n",
    "print(digits.target[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Clasificación de dígitos escritos a mano con regresión logística (multiclase)\n",
    "\n",
    "Se pide aplicar regresión logística para obtener un clasificador para este problema multiclase. Probar con varios valores del parámetro `C` para obtener el mejor rendimiento sobre un conjunto de prueba. \n",
    "\n",
    "Algunas observaciones:\n",
    "\n",
    "* Originalmente, en `digits.images` tenemos un array con 1797 arrays 8x8 (es decir, cada imagen viene en 64 pixeles distribuidos en 8 filas y 8 clolumnas). Para poder aplicar los clasificadores, cada imagen debe ser un vector de 64 componentes. Esto se consigue de manera sencilla con el método `reshape`de numpy. \n",
    "* Es necesario separar el conjunto de imágenes en entrenamiento y prueba. No olvidar hacerlo de manera estratificada (usando la opción `stratify`de `train_test_split`)\n",
    "* Medir el rendimiento usando `score`. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ejercicio\n",
    "Tal como indica el enunciado, el primer paso para poder obtener un clasificador multiclase para este problema, es transformar el vector de las imágenes un uno de 64 componentes. Para ello obtenemos el número de imágenes (*no_img*) y utilizamos el método `reshape`de *numpy*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "no_img, rows, cols = digits.images.shape\n",
    "imagesData = np.reshape(digits.images,(no_img, 64))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A continuación separamos los datos de las imágenes que tenemos en un conjunto de entrenamiento y otro prueba como hemos visto en sesiones anteriores mediante `train_test_split`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(imagesData, digits.target, stratify=digits.target, random_state=462)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ya que más adelante se va a calcular el rendimiento de aplicar `LogisticRegression`con distintos valores de `C`, se ha definido la función *logRegClas* la cual calcula el rendimiento para los distintos valores de `C` que se indiquen. Además de mostrar los rendimientos obtenidos, como resultado, devuelve el mejor clasificador, el valor de `C` con el que se obtiene y su rendimiento."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def logRegClas(C_vals, X_train, y_train, X_test, y_test):\n",
    "    bestScore = -1\n",
    "    bestC = C_vals[0]\n",
    "    bestLogReg = LogisticRegression()\n",
    "    for value in C_vals:\n",
    "        logreg = LogisticRegression(max_iter=15000, C = value).fit(X_train, y_train)\n",
    "        score = logreg.score(X_test, y_test)\n",
    "        if score > bestScore:\n",
    "            bestScore = score\n",
    "            bestC = value\n",
    "            bestLogReg = logreg\n",
    "        print(\"Rendimiento sobre el conjunto de entrenamiento, valor de C={}: {:.3f}\".format(value, logreg.score(X_train, y_train)))\n",
    "        print(\"Rendimiento sobre el conjunto de test, valor de C={}: {:.3f}\".format(value, score))\n",
    "    return [bestLogReg, bestC, bestScore]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rendimiento sobre el conjunto de entrenamiento, valor de C=0.01: 0.993\n",
      "Rendimiento sobre el conjunto de test, valor de C=0.01: 0.984\n",
      "Rendimiento sobre el conjunto de entrenamiento, valor de C=0.1: 1.000\n",
      "Rendimiento sobre el conjunto de test, valor de C=0.1: 0.976\n",
      "Rendimiento sobre el conjunto de entrenamiento, valor de C=10: 1.000\n",
      "Rendimiento sobre el conjunto de test, valor de C=10: 0.969\n",
      "Rendimiento sobre el conjunto de entrenamiento, valor de C=100: 1.000\n",
      "Rendimiento sobre el conjunto de test, valor de C=100: 0.967\n",
      "Mejor rendimiento: 0.984, valor de C=0.01\n"
     ]
    }
   ],
   "source": [
    "C_vals = [0.01, 0.1, 10, 100]\n",
    "bestLogReg, bestC, bestScore = logRegClas(C_vals, X_train, y_train, X_test, y_test)\n",
    "print(\"Mejor rendimiento: {:.3f}, valor de C={}\".format(bestScore, bestC))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El mejor rendimiento sobre el conjunto de prueba se obtiene con la regularización *`C`= 0.01*. Observar que con los otro valores de regularización (han ido incrementando respecto a 0.01, lo cual significa, menor regularización) se obtiene el máximo rendimiento sobre el conjunto de entrenamiento, lo que significa que se está produciendo un sobreajuste."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Clasificación binaria usando regresión logística\n",
    "\n",
    "Una vez encontrado un buen clasificador para el problema multiclase, mostrar la matriz de confusión finalmente obtenida sobre el conjunto de prueba. También mostrar las imágenes de un par de dígitos respectivamente hayan sido bien y mal clasificados.  Usando `predict_proba` mostrar las predicciones que realiza el modelo sobre esos dos dígitos, y comentar los resultados. \n",
    "\n",
    "Deducir de la matriz de confusión un par de dígitos que en general cueste más trabajo distinguir entre sí, y extraer de los datos sólo las imágenes correspondientes a esos dos dígitos. Por ejemplo: si se observa que entre el 8 y el 9 hay más errores de predicción, habría que extraer todas las imágenes de ochos y nueves y crear un conjunto de datos con ellas.  \n",
    "\n",
    "Crear a partir de esos datos extraidos,  conjuntos de entrenamiento y prueba para aprender con regresión logística un clasificador que sea \"especialista\" es distinguir un dígito del otro. Como antes, probar con varios valores del parámetro para intentar obtener un buen rendimiento sobre el conjunto de prueba.\n",
    "\n",
    "**Nota**: para extraer los datos correspondiente a un dígito, aplicar selección condicional de numpy. Por ejemplo, con `digits.target==8` obtenemos un array booleano en el que están a `True` solo las posiciones de los ejemplos cuyo target es 8. Si tenemos un array `a`, entonces `a[digits.target ==8]` es el array en el que se han seleccionado sólo esas posiciones.  \n",
    "`  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ejercicio\n",
    "Ahora que tenemos el mejor clasificador (*bestLogReg*) vamos a obtener la matriz de confusión (`confusion_matrix`), que dada las clasificaciones reales y las predicciones, evalúa la precisión de una clasificación."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Matriz de confusion\n",
    "prediction = bestLogReg.predict(X_test)\n",
    "from sklearn.metrics import confusion_matrix\n",
    "conf_matrix = confusion_matrix(y_test, prediction)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Busquemos un valor que haya sido clasificado correctamente y otro que no. Para ello vamos a coger el primer valor que encontremos de la predicción (*prediction*), cuya clasificación real (*y_test*) coincida y otro que sea errónea.<br>\n",
    "Empezaremos mostrando la imagen del dígito que se ha clasificado adecuadamente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 288x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Número a clasificar:  7\n",
      "Clasificación:  7\n"
     ]
    }
   ],
   "source": [
    "ok_index = -1\n",
    "ko_index = -1\n",
    "for i in range(len(prediction)):\n",
    "    if ok_index == -1 and prediction[i] == y_test[i]:\n",
    "        ok_index = i\n",
    "    if ko_index == -1 and prediction[i] != y_test[i]:\n",
    "        ko_index = i\n",
    "\n",
    "# Dígito bien clasificado\n",
    "plt.gray()\n",
    "plt.matshow(X_test[ok_index].reshape(8,8)) \n",
    "plt.show()\n",
    "print(\"Número a clasificar: \", prediction[ok_index])\n",
    "print(\"Clasificación: \",y_test[ok_index])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.07517020e-05, 1.52567561e-05, 1.58378572e-04, 2.54607515e-03,\n",
       "        1.05343465e-04, 1.40321021e-05, 6.66701665e-07, 9.96926851e-01,\n",
       "        1.75999567e-04, 4.66453308e-05]])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bestLogReg.predict_proba([X_test[ok_index]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Viendo la imagen podemos deducir que es un 7 y con `predict_proba` comprobamos la seguridad que tenía en cada predicción.<br>\n",
    "Ahora vamos a repetir esta comprobación pero con un dígito que no ha sido bien clasificado."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 288x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Número a clasificar:  1\n",
      "Clasificación:  8\n"
     ]
    }
   ],
   "source": [
    "# Dígito mal clasificado\n",
    "plt.gray()\n",
    "plt.matshow(X_test[ko_index].reshape(8,8)) \n",
    "plt.show() \n",
    "\n",
    "print(\"Número a clasificar: \", prediction[ko_index])\n",
    "print(\"Clasificación: \",y_test[ko_index])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[6.09455754e-03, 9.34919876e-01, 1.97891814e-04, 3.39517104e-05,\n",
       "        2.61864683e-02, 6.60782999e-04, 1.05311904e-03, 3.80671376e-04,\n",
       "        1.58042806e-02, 1.46684004e-02]])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bestLogReg.predict_proba([X_test[ko_index]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como podemos ver en la imagen, es díficil identificar qué numero es. Y viendo el resultado de `predict_proba`podemos ver que las clasificaciones más probables serían 1, 4, 8 y 9"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos a mostrar la matriz de confusión"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[45  0  0  0  0  0  0  0  0  0]\n",
      " [ 0 46  0  0  0  0  0  0  0  0]\n",
      " [ 0  0 44  0  0  0  0  0  0  0]\n",
      " [ 0  0  0 43  0  3  0  0  0  0]\n",
      " [ 0  0  0  0 45  0  0  0  0  0]\n",
      " [ 0  0  0  0  0 45  0  0  0  1]\n",
      " [ 0  1  0  0  0  0 44  0  0  0]\n",
      " [ 0  0  0  0  0  0  0 45  0  0]\n",
      " [ 0  1  1  0  0  0  0  0 41  0]\n",
      " [ 0  0  0  0  0  0  0  0  0 45]]\n"
     ]
    }
   ],
   "source": [
    "print(conf_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Viendo el resultado podemos deducir que el número que mejor clasifica es el 2, y los que peor el 3 y el 8. Vamos a extraer los datos correspondientes a estos 2 dígitos que más cuesta clasificar, para seguidamente crear a partir de estos un conjunto de entrenamiento y otro de prueba, con el objetivo de obtener un clasificador (mediante regresión logística) \"especialista\" en distinguir un dígito del otro.<br>\n",
    "Como en experimentos anteriores, vamos a probar con distintos valores de `C` haciendo uso de la función definida *bestLogReg* y ver los rendimientos obtenidos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "filter = (digits.target == 3) | (digits.target == 8)\n",
    "Y_filter_data = digits.target[filter]\n",
    "X_filter_data = imagesData[Y_filter_data]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rendimiento sobre el conjunto de entrenamiento, valor de C=0.01: 1.000\n",
      "Rendimiento sobre el conjunto de test, valor de C=0.01: 1.000\n",
      "Rendimiento sobre el conjunto de entrenamiento, valor de C=0.1: 1.000\n",
      "Rendimiento sobre el conjunto de test, valor de C=0.1: 1.000\n",
      "Rendimiento sobre el conjunto de entrenamiento, valor de C=10: 1.000\n",
      "Rendimiento sobre el conjunto de test, valor de C=10: 1.000\n",
      "Rendimiento sobre el conjunto de entrenamiento, valor de C=100: 1.000\n",
      "Rendimiento sobre el conjunto de test, valor de C=100: 1.000\n",
      "Mejor rendimiento: 1.00, valor de C=0.01\n"
     ]
    }
   ],
   "source": [
    "X_f_train, X_f_test, y_f_train, y_f_test = train_test_split(X_filter_data, Y_filter_data, stratify=Y_filter_data, random_state=462)\n",
    "\n",
    "C_vals_f = [0.01, 0.1, 1, 10, 100]\n",
    "bestLogReg_f, bestC_f, bestScore_f =logRegClas(C_vals, X_f_train, y_f_train, X_f_test, y_f_test)\n",
    "print(\"Mejor rendimiento: {:.2f}, valor de C={}\".format(bestScore_f, bestC_f))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A pesar de aplicar distintos valores de regularización, se obtiene siempre el máximo rendimiento, tanto en el conjunto de entrenamiento como en el de pruebas, lo que signfica que todos los modelos, tienen sobreajuste."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 Clasificación de dígitos con SVC (multiclase)\n",
    "\n",
    "Volviendo al problema multiclase de 2.1, aplicar ahora máquinas de vectores soporte con kernel (`SVC`) para el problema de reconocer los dígitos. Probar al menos con varios valores de los parámetros `C` y `gamma`, para obtener un buen rendimiento sobre el conjunto de prueba. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ejercicio\n",
    "Ahora vamos a aplicar `SVC`y ver el rendimiento que obtenemos con distintgos valores de regularización `C` y de `gamma` (anchura de kernel). Para ellos vamos a hacer un bucle similar al de la función *logRegClas* pero aplicando máquinas de vectores soporte con kernel (`SVC`) y la combinación de las distintas posibilidades de `C` y `gamma`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rendimiento sobre el conjunto de entrenamiento, valor de C=0.01, valor de gamma=0.01: 0.102\n",
      "Rendimiento sobre el conjunto de test, valor de C=0.01, valor de gamma=0.01: 0.102\n",
      "Rendimiento sobre el conjunto de entrenamiento, valor de C=0.01, valor de gamma=0.1: 0.102\n",
      "Rendimiento sobre el conjunto de test, valor de C=0.01, valor de gamma=0.1: 0.102\n",
      "Rendimiento sobre el conjunto de entrenamiento, valor de C=0.01, valor de gamma=10: 0.102\n",
      "Rendimiento sobre el conjunto de test, valor de C=0.01, valor de gamma=10: 0.102\n",
      "Rendimiento sobre el conjunto de entrenamiento, valor de C=0.01, valor de gamma=50: 0.102\n",
      "Rendimiento sobre el conjunto de test, valor de C=0.01, valor de gamma=50: 0.102\n",
      "Rendimiento sobre el conjunto de entrenamiento, valor de C=0.1, valor de gamma=0.01: 0.102\n",
      "Rendimiento sobre el conjunto de test, valor de C=0.1, valor de gamma=0.01: 0.102\n",
      "Rendimiento sobre el conjunto de entrenamiento, valor de C=0.1, valor de gamma=0.1: 0.102\n",
      "Rendimiento sobre el conjunto de test, valor de C=0.1, valor de gamma=0.1: 0.102\n",
      "Rendimiento sobre el conjunto de entrenamiento, valor de C=0.1, valor de gamma=10: 0.102\n",
      "Rendimiento sobre el conjunto de test, valor de C=0.1, valor de gamma=10: 0.102\n",
      "Rendimiento sobre el conjunto de entrenamiento, valor de C=0.1, valor de gamma=50: 0.102\n",
      "Rendimiento sobre el conjunto de test, valor de C=0.1, valor de gamma=50: 0.102\n",
      "Rendimiento sobre el conjunto de entrenamiento, valor de C=1, valor de gamma=0.01: 1.000\n",
      "Rendimiento sobre el conjunto de test, valor de C=1, valor de gamma=0.01: 0.887\n",
      "Rendimiento sobre el conjunto de entrenamiento, valor de C=1, valor de gamma=0.1: 1.000\n",
      "Rendimiento sobre el conjunto de test, valor de C=1, valor de gamma=0.1: 0.104\n",
      "Rendimiento sobre el conjunto de entrenamiento, valor de C=1, valor de gamma=10: 1.000\n",
      "Rendimiento sobre el conjunto de test, valor de C=1, valor de gamma=10: 0.102\n",
      "Rendimiento sobre el conjunto de entrenamiento, valor de C=1, valor de gamma=50: 1.000\n",
      "Rendimiento sobre el conjunto de test, valor de C=1, valor de gamma=50: 0.102\n",
      "Rendimiento sobre el conjunto de entrenamiento, valor de C=10, valor de gamma=0.01: 1.000\n",
      "Rendimiento sobre el conjunto de test, valor de C=10, valor de gamma=0.01: 0.902\n",
      "Rendimiento sobre el conjunto de entrenamiento, valor de C=10, valor de gamma=0.1: 1.000\n",
      "Rendimiento sobre el conjunto de test, valor de C=10, valor de gamma=0.1: 0.104\n",
      "Rendimiento sobre el conjunto de entrenamiento, valor de C=10, valor de gamma=10: 1.000\n",
      "Rendimiento sobre el conjunto de test, valor de C=10, valor de gamma=10: 0.102\n",
      "Rendimiento sobre el conjunto de entrenamiento, valor de C=10, valor de gamma=50: 1.000\n",
      "Rendimiento sobre el conjunto de test, valor de C=10, valor de gamma=50: 0.102\n",
      "Rendimiento sobre el conjunto de entrenamiento, valor de C=100, valor de gamma=0.01: 1.000\n",
      "Rendimiento sobre el conjunto de test, valor de C=100, valor de gamma=0.01: 0.902\n",
      "Rendimiento sobre el conjunto de entrenamiento, valor de C=100, valor de gamma=0.1: 1.000\n",
      "Rendimiento sobre el conjunto de test, valor de C=100, valor de gamma=0.1: 0.104\n",
      "Rendimiento sobre el conjunto de entrenamiento, valor de C=100, valor de gamma=10: 1.000\n",
      "Rendimiento sobre el conjunto de test, valor de C=100, valor de gamma=10: 0.102\n",
      "Rendimiento sobre el conjunto de entrenamiento, valor de C=100, valor de gamma=50: 1.000\n",
      "Rendimiento sobre el conjunto de test, valor de C=100, valor de gamma=50: 0.102\n",
      "\n",
      "Mejor rendimiento: 0.902, valor de C=10, valor de gamma=0.01\n",
      "Rendimiento sobre el conjunto de entrenamiento: 1.0\n",
      "Rendimiento sobre el conjunto de test: 0.9022222222222223\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "import itertools\n",
    "svm_score = -1\n",
    "svm_bestScore = -1\n",
    "svm_bestScoreTrain = -1\n",
    "svm_bestC = -1\n",
    "svm_bestGamma = -1\n",
    "C_vals_svm = [0.01, 0.1, 1, 10, 100]\n",
    "Gamma_vals = [0.01, 0.1, 10, 50]\n",
    "for C_val, gamma_val in itertools.product(C_vals_svm, Gamma_vals):\n",
    "    svm = SVC(C=C_val, gamma=gamma_val).fit(X_train, y_train)\n",
    "    svm_score = svm.score(X_test, y_test)\n",
    "    svm_score_train = svm.score(X_train, y_train)\n",
    "    if svm_score > svm_bestScore:\n",
    "        svm_bestScore = svm_score\n",
    "        svm_bestC = C_val\n",
    "        svm_bestGamma = gamma_val\n",
    "        svm_bestScoreTrain = svm_score_train\n",
    "    print(\"Rendimiento sobre el conjunto de entrenamiento, valor de C={}, valor de gamma={}: {:.3f}\".format(C_val, gamma_val, svm_score_train))\n",
    "    print(\"Rendimiento sobre el conjunto de test, valor de C={}, valor de gamma={}: {:.3f}\".format(C_val, gamma_val, svm_score))\n",
    "print(\"\\nMejor rendimiento: {:.3f}, valor de C={}, valor de gamma={}\".format(svm_bestScore, svm_bestC, svm_bestGamma))\n",
    "print(\"Rendimiento sobre el conjunto de entrenamiento: {}\".format(svm_bestScoreTrain))\n",
    "print(\"Rendimiento sobre el conjunto de test: {}\".format(svm_bestScore))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Obtenemos el mejor rendimiento con *`C`=10* y *`gamma`=0.01, aunque sobre el conjunto de entrenamiento se produce sobreajuste."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
