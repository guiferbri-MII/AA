{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Aprendizaje basado en instancias"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Procesado de los datos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El conjunto de datos sobre cáncer de mama está incluido en *Scikit-learn*, se obtiene usando la función `load_breast_cancer` incluida en la librería `sklearn.datasets`. Este conjunto de datos contiene 569 ejemplos con 30 características sobre clasificaciones de cáncer de mama, con dos clasificaciones posibles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_breast_cancer\n",
    "\n",
    "cancer = load_breast_cancer()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Este conjunto de datos es un diccionario con varios campos:\n",
    "* `data`: Es el conjunto de datos, se trata de un array en el que cada componente es un array con las características de cada instancia.\n",
    "* `target`: Es el conjunto de valores de clasificación para cada instancia. Es un array del mismo tamaño que `data`, en el que se indica el valor de clasificación de cada instancia, en el mismo orden en que éstas se encuentran en el array `data`.\n",
    "* `DESCR`: Es una descripción del conjunto de datos.\n",
    "* `target_names`: Es un array con los nombres de cada valor de clasificación.\n",
    "* `feature_names`: Es un array con los nombres de cada característica.\n",
    "\n",
    "Almacenamos los datos en las variables `X_data`, `y_data`, `X_names` e `y_names`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_data, y_data, X_names, y_names = \\\n",
    "    cancer.data, cancer.target, cancer.feature_names, cancer.target_names"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ejemplos aislados (*outliers*)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Un ejemplo aislado (*outlier* en inglés) es un ejemplo de entrenamiento que está rodeado por ejemplos que no pertenecen a su misma clase. La presencia de ejemplos aislados en un conjunto de entrenamiento puede deberse a:\n",
    "\n",
    "* Un error en los datos\n",
    "* Una cantidad insuficiente de ejemplos de la clase de los ejemplos aislados\n",
    "* La existencia de características que no se están teniendo en cuenta\n",
    "* Clases desbalanceadas \n",
    "\n",
    "En el contexto de la clasificación basada en instancias mediante el algoritmo **k**-*NN*, los ejemplos aislados generan ruido que disminuye el rendimiento del clasificador. Dados dos números naturales, $k$ y $r$, con $k>r$, decimos que un ejemplo es ($k$,$r$)-aislado si en sus $k$ vecinos más cercanos hay más de $r$ ejemplos que no pertenecen a su misma clase."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En este ejercicio vamos a identificar ejemplos ($k$,$r$)-aislados en el conjunto de datos y vamos a comparar el rendimiento del clasificador **K**-*NN* con y sin estos ejemplos. Para ello vamos a utilizar la clase `NearestNeighbors` de *Scikit-learn*, incluida en la librería `sklearn.neighbors`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import NearestNeighbors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Contenido del ejercicio"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El ejercicio consiste en\n",
    "\n",
    "* Investigar la clase `NearestNeighbors` de *Scikit-learn* y cómo se usa para obtener los vecinos más cercanos a un ejemplo dado dentro de un conjunto de datos, con respecto a una medida de distancia.\n",
    "* Definir la función `buscaOutliers` que dados dos números naturales `k` y `r`, devuelve la lista de los índices de los ejemplos del conjunto de entrenamiento sobre el cáncer que son (`k`,`r`)-aislados. Es decir, la lista de los índices de los ejemplos del conjunto de entrenamiento `X_data` para los que en sus `k` vecinos más cercanos hay más de `r` ejemplos con una clasificación distinta a la del propio ejemplo.\n",
    "* Construir un segundo conjunto de datos `Xo_data` obtenido a partir del inicial eliminando todos los ejemplos (5,3)-aislados.\n",
    "* Construir dos modelos de decisión (para valores de `p` y `k` coherentes con la búsqueda de ejemplos aislados), uno para cada conjunto de datos considerado `X_data` y `Xo_data`, realizando en ambos casos una separación del $30$% de datos de prueba y $70$% de datos de entrenamiento.\n",
    "* Comparar el rendimiento de ambos modelos sobre su correspondiente conjunto de prueba.\n",
    "\n",
    "El **desarrollo tiene que estar razonado**, indicando en cada apartado qué se está haciendo, **demostrando así el conocimiento adquirido en este módulo**. ¿Qué conclusiones puedes sacar de lo aprendido sobre aprendizaje basado en instancias?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NearestNeighbors\n",
    "La clase `NearestNeighbors` es un modelo dentro de la familia de 'modelos basado en vecinos cercanos' (k-NN) de tipo no supervisado. Esta clase devuelve el número de vecinos más cercanos en distancia. Este número de vecinos es indicado mediante el parámetro *n_neighbors*. Entre otros de los parámetros que admite se encuentra *algorithm*, que sirve para indicar el algoritmo a utilizar para calcular a los vecinos cercanos. Por defecto tiene el valor *auto* lo que significa que decidirá cual es el mas apropiado en funcion de los valores de ejemplos que se utilizan para el entrenamiento."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### buscaOutliers\n",
    "\n",
    "A continuación se define la función `buscaOutliers` que va a eliminar aquellas ejemplos que estan rodeados de instancias con diferente clasificacion, es decir, quitar ruido. Dado *k* vecinos y *r* ejemplos, devuelve los índices de los ejemplos del conjunto de entrenamiento en los cuales en sus *k* vecinos mas cercanos hay mas de *r* ejemplos con una clasificación distinta a la del ejemplo. Para ello se va a hacer uso de la clase investigada anteriormente a la cual le indicaremos los *k* vecinos que queremos obtener del conjunto de entrenamiento *X_data*.\n",
    "\n",
    "Esta clase devuelve un array del tamaño del número de elementos del conjunto de entrenamiento. Cada elemento de este array contiene otro en el que la primera posición es el índice de cada elemento del conjunto de entrenamiento y los siguientes son los índices de sus *k-1* vecinos más cercanos.\n",
    "\n",
    "Una vez obtenidos estos índices los va a recorrer para obtener la clasificación de cada elemento del conjunto de entrenamiento. Para cada vecino cercano de ese elemento, va a comprobar si la clasificación del vecino es distinta a la del elemento que se esta revisando. En caso afirmativo, lo contabilizará como un ejemplo.\n",
    "\n",
    "Tras verificar todos los vecinos cercanos del elemento, comprueba si el número total de ejemplos contabilizados es mayor que los *r* ejemplos, si es así lo añadirá a la lista *outliners* que contiene el resultado de esta función con los índices de los ejemplos con una clasificación distinta más cercanos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "def buscaOutliers(k, r):\n",
    "    nbrs = NearestNeighbors(n_neighbors=k).fit(X_data)\n",
    "    distances, indices = nbrs.kneighbors(X_data)\n",
    "    outliners = []    \n",
    "    for elements in indices:\n",
    "        element = elements[0]\n",
    "        elementClass = y_data[element]\n",
    "        neighborsClass = 0\n",
    "        for neighbour in elements[1:]:\n",
    "            nbClass = y_data[neighbour]\n",
    "            if nbClass != elementClass:\n",
    "                neighborsClass += nbClass\n",
    "        if neighborsClass > r:\n",
    "            outliners.append(element)\n",
    "    return outliners\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El siguiente paso es eliminar los (5,3)-aislados ejemplos del conjunto de entrenamiento. Utilizando la función `buscaOutliers` obtenemos los índices de los elementos aislados que queremos descartar y mediante el método *delete* de *numpy* los eliminamos tanto del conjunto de entrenamiento *X_data*, obteniendo `Xo_data`; como del conjunto de los valores de clasificación *y_data* obteniendo `yo_data`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "outliners = buscaOutliers(5,3)\n",
    "Xo_data =  np.delete(X_data, outliners, axis=0)\n",
    "yo_data =  np.delete(y_data, outliners, axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modelos de decisión\n",
    "\n",
    "Ahora vamos a aplicar el algoritmo k-NN al conjunto de entrenamiento *X_data* y *Xo_data*. En primer lugar dividimos los conjuntos de datos, respectivamente, en un conjunto de prueba y en un conjunto de entrenamiento. Como se indica, para esta división se ha aplicado una separación del 30% para datos de prueba, siendo el 70% restante para entrenamiento."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_data,y_data,test_size = 0.30, random_state=4861, stratify=y_data)\n",
    "Xo_train, Xo_test, yo_train, yo_test = train_test_split(Xo_data,yo_data,test_size = 0.30, random_state=4861, stratify=yo_data)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Una vez tenemos los conjuntos de entrenamiento (\\**_train*) y los de pruebas (\\**_test*) aplicamos el algoritmo k-NN. El número de vecinos (*n_neighbors*, parámetro *k*) elegido ha sido 5, para mantener la coherencia y poder compararlo con el conjunto de datos *Xo_data*, que no contiene los elementos aislados de los 5 vecinos más cercanos. Para la distancia (parámetro *p*) se ha elegido el valor 1 (distancia de Manhattan) porque las características que se están midiendo (area, textura, simetria..) no tienen nada en común.\n",
    "\n",
    "Primero lo aplicamos sobre el conjunto de entrenamiento original (*X_data*) y calculamos su rendimiento haciendo uso del método score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9649122807017544"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "p = 1\n",
    "k = 5\n",
    "knn = KNeighborsClassifier(n_neighbors=k,p=p)\n",
    "knn.fit(X_data,y_data)\n",
    "knn.score(X_test,y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A continuación lo aplicamos sobre el conjunto sin los elementos aislados (*Xo_data*) y calculamos el rendimiento."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9761904761904762"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "knno = KNeighborsClassifier(n_neighbors=k,p=p)\n",
    "knno.fit(Xo_data,yo_data)\n",
    "knno.score(Xo_test,yo_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conclusion\n",
    "\n",
    "Al comparar ambos rendimientos vemos que sobre el conjunto con los ejemplos (5,3)-aislados elimminados (*Xo_data*) ha mejorado, aunque sea levemente, ya que hemos eliminado ruido ayudando de esta forma al modelo. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
