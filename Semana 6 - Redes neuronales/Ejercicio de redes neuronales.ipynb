{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Redes neuronales (ejercicio)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Importante: comentar adecuadamente cada paso realizado**, relacionándolo con lo visto en la teoría."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parte 1: aplicación de redes neuronales a clasificación (análisis de sentimientos)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se pide aplicar un modelo de redes neuronales al problema de decidir si una crítica de cine es positiva o negativa. Para ello volvemos a usar los datos de IMDB (Internet Movie Database) que vimos en el módulo 2 (modelo probabilístico).\n",
    "\n",
    "Hacerlo usando los dos sistemas vistos, comparando los resultados:\n",
    "* Scikit learn: usar `MLPClassifier`\n",
    "* Keras con Tensorflow: usar `Sequential` y capas tipo `Dense` con la arquitectura adecuda.\n",
    "\n",
    "\n",
    "Aunque ya hemos visto que los datos están disponibles en http://ai.stanford.edu/~amaas/data/sentiment/ , en este caso pedimos cargar los datos usando la utilidad `imdb`de Keras. Se puede consultar en el manual de Keras: https://keras.io/datasets/ Cargarlos con `imdb.load_data` y usar los datos cargados como punto de partida a este ejercicio (tanto para su aplicar scikit learn como para aplicar keras). Prestar atención al formato en el que se cargar, que no es el mismo que hamos visto hasta ahora.  \n",
    "\n",
    "Los textos han de ser vectorizados para que se puedan ser procesados por una red. Para esto, tenemos varias alternativas, usar una de ellas:\n",
    "\n",
    "* Vectorizando \"manualmente\", definiendo una función en python que lo haga.\n",
    "* Vectorizadores de scikit learn (ya vistos)\n",
    "* Herramientas de vectorización de keras: https://keras.io/preprocessing/text/\n",
    "\n",
    "Mostrar algunas pruebas realizadas con distintas arquitecturas y/o hiperparámetros. No es necesario ser muy exhaustivo ni usar `GridSearchCV` en scikit learn ni el equivalente en keras. Tan solo mostrar alguna experimentación y ajuste manual.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ejercicio\n",
    "Empecemos por cargar los datos de las críticas de `imdb` utilizando Keras. El método `load_data` devuelve dos tuplas de arrays: uno con el conjunto de entrenamiento y otro con el conjunto de prueba. Cada tupla tiene los datos (*X_train_code*, *X_test_code*) que son una lista de índices, y su correspondiente clasificación (*y_train*, *y_test*) en 1 (positivo) y 0 (negativo). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((25000,), (25000,))"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Importar datos\n",
    "import tensorflow as tf \n",
    "from tensorflow import keras\n",
    "(X_train_code, y_train), (X_test_code, y_test) = keras.datasets.imdb.load_data()\n",
    "X_train_code.shape, X_test_code.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La lista de índices de los datos son palabras codificadas, es decir, cada índice es una palabra codificada, por tanto una crítica completa es el conjunto de todas los índices de las palabras. Como queremos trabajar con las críticas, vamos a decodificarlas, tanto el conjunto de entrenamiento como el de prueba. Para ello utilizamos el método `get_word_index` con el que obtenemos el diccionario de palabras y el índice correspondiente a cada una de ellas. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Decodificar\n",
    "word_index = keras.datasets.imdb.get_word_index()\n",
    "inverted_word_index = dict((i, word) for (word, i) in word_index.items())\n",
    "\n",
    "X_train_decode = []\n",
    "for critic in X_train_code:\n",
    "    X_train_decode.append(\" \".join([inverted_word_index.get(i, '') for i in critic]))\n",
    "\n",
    "X_test_decode = []\n",
    "for critic in X_test_code:\n",
    "    X_test_decode.append(\" \".join([inverted_word_index.get(i, '') for i in critic]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para procesar los textos que hemos decodificado es necesario vectorizarlos. Vamos a aplicar los vectorizadores de scikit learn que hemos visto en sesiones anteriores. Primero entrenamos el vectorizador y a continuación aplicamos la vectorización a ambos grupos, para obtener los conjuntos con los que vamos a trabajar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "vect = CountVectorizer().fit(X_train_decode)\n",
    "X_train = vect.transform(X_train_decode)\n",
    "X_test = vect.transform(X_test_decode)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora que tenemos los datos, vamos a aplicar dos modelo de redes neuronales. Empecemos primero por el de scikit_learn `MLPClassifier` dentro del módulo `neural_network`, que permitirá usar las redes multicapa hacia adelante. Vamos a ver el rendimiento que obtenemos con los valores por defecto, una capa oculta y 100 unidades en esa capa, y con el método `lbfgs`, ya que no necesita tantos ajustes y con los datos que manejamos (25.000 ejemplos) se espera que funcione relativamente bien."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rendimiento en entrenamiento: 1.00\n",
      "Rendimiento en el conjunto de prueba: 0.86\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "mlp = MLPClassifier(solver=\"lbfgs\", max_iter=1000, random_state=42)\n",
    "mlp.fit(X_train, y_train)\n",
    "\n",
    "print(\"Rendimiento en entrenamiento: {:.2f}\".format(mlp.score(X_train, y_train)))\n",
    "print(\"Rendimiento en el conjunto de prueba: {:.2f}\".format(mlp.score(X_test, y_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El rendimiento obtenido no es muy bueno, de hecho se puede ver que sobre el conjunto de entrenamiento se produce algo de sobreajuste. Vamos a aplicar regularización, mediente el parámetro *alpha*, a ver si conseguimos que mejore algo el rendimiento."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rendimiento en entrenamiento: 1.00\n",
      "Rendimiento en el conjunto de prueba: 0.87\n",
      "Rendimiento en entrenamiento: 1.00\n",
      "Rendimiento en el conjunto de prueba: 0.86\n"
     ]
    }
   ],
   "source": [
    "mlp_a1 = MLPClassifier(solver=\"lbfgs\", max_iter=1000, alpha=1, random_state=42)\n",
    "mlp_a1.fit(X_train, y_train)\n",
    "print(\"Rendimiento en entrenamiento: {:.2f}\".format(mlp_a1.score(X_train, y_train)))\n",
    "print(\"Rendimiento en el conjunto de prueba: {:.2f}\".format(mlp_a1.score(X_test, y_test)))\n",
    "\n",
    "mlp_a05 = MLPClassifier(solver=\"lbfgs\", max_iter=1000, alpha=0.05, random_state=42)\n",
    "mlp_a05.fit(X_train, y_train)\n",
    "print(\"Rendimiento en entrenamiento: {:.2f}\".format(mlp_a05.score(X_train, y_train)))\n",
    "print(\"Rendimiento en el conjunto de prueba: {:.2f}\".format(mlp_a05.score(X_test, y_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A pesar de aplicar regularización, se obtienen resultados similares.<br><br>\n",
    "Veamos ahora qué resultados obtenemos aplicando *Keras* con Tensorflow usando el módulo `Sequential` y capas tipo `Dense`. Cada unidad de estas capas recibe tantas conexiones como unidades en la capa anterior más un sesgo. Siguiendo el ejercicio visto, vamos a crear una red neuronal con la misma configuración:\n",
    "- Dos capas tipo `Dense`, con 300 y 100 unidades, respectivamente, ambas con función de activación ReLU.\n",
    "- Una última capa (salida) de 1 unidad, con función de activación `sigmoide`. Tiene una sola unidad porque al usar sigmoide, devolverá un valor entre 0 y 1.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-01-05 09:31:11.599130: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "model = keras.models.Sequential()\n",
    "model.add(keras.layers.Dense(300, activation=\"relu\"))\n",
    "model.add(keras.layers.Dense(100, activation=\"relu\"))\n",
    "model.add(keras.layers.Dense(1, activation=\"sigmoid\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Con el método `compile` especificamos la función de pérdida, coste (`loss`); el optimizador (`optimizer`) para buscar los pesos adecuados y la métrica (`metrics`) para medir el rendimiento del modelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss=\"binary_crossentropy\", optimizer=\"sgd\", metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora podemos entrenar el modelo mediante el método `fit` que recibe el el conjunto de entrenamiento, el número de *epochs* y un conjunto de validación para ir midiendo el rendimiento durante el proceso. Este último es opcional, pero vamos a utilizarlo para seguir el ejemplo visto en la sesión.<br>\n",
    "Para obtener este conjunto de validación vamos a coger 8000 ejemplos para el conjunto de entrenamiento y otros 8000 para el de validación."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:448: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/sequential/dense/embedding_lookup_sparse/Reshape_1:0\", shape=(None,), dtype=int32), values=Tensor(\"gradient_tape/sequential/dense/embedding_lookup_sparse/Reshape:0\", shape=(None, 300), dtype=float32), dense_shape=Tensor(\"gradient_tape/sequential/dense/embedding_lookup_sparse/Cast:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "782/782 [==============================] - 5s 5ms/step - loss: 0.5631 - accuracy: 0.7222\n",
      "Epoch 2/30\n",
      "782/782 [==============================] - 3s 4ms/step - loss: 0.4482 - accuracy: 0.8098\n",
      "Epoch 3/30\n",
      "782/782 [==============================] - 3s 4ms/step - loss: 0.3865 - accuracy: 0.8382\n",
      "Epoch 4/30\n",
      "782/782 [==============================] - 3s 4ms/step - loss: 0.3545 - accuracy: 0.8530\n",
      "Epoch 5/30\n",
      "782/782 [==============================] - 3s 4ms/step - loss: 0.3245 - accuracy: 0.8654\n",
      "Epoch 6/30\n",
      "782/782 [==============================] - 3s 4ms/step - loss: 0.3056 - accuracy: 0.8764\n",
      "Epoch 7/30\n",
      "782/782 [==============================] - 3s 4ms/step - loss: 0.2846 - accuracy: 0.8824\n",
      "Epoch 8/30\n",
      "782/782 [==============================] - 3s 4ms/step - loss: 0.2695 - accuracy: 0.8913\n",
      "Epoch 9/30\n",
      "782/782 [==============================] - 3s 4ms/step - loss: 0.2596 - accuracy: 0.8950\n",
      "Epoch 10/30\n",
      "782/782 [==============================] - 3s 4ms/step - loss: 0.2449 - accuracy: 0.9014\n",
      "Epoch 11/30\n",
      "782/782 [==============================] - 3s 4ms/step - loss: 0.2267 - accuracy: 0.9084\n",
      "Epoch 12/30\n",
      "782/782 [==============================] - 4s 5ms/step - loss: 0.2212 - accuracy: 0.9124\n",
      "Epoch 13/30\n",
      "782/782 [==============================] - 4s 5ms/step - loss: 0.2103 - accuracy: 0.9148\n",
      "Epoch 14/30\n",
      "782/782 [==============================] - 4s 5ms/step - loss: 0.1979 - accuracy: 0.9227\n",
      "Epoch 15/30\n",
      "782/782 [==============================] - 4s 5ms/step - loss: 0.1892 - accuracy: 0.9251\n",
      "Epoch 16/30\n",
      "782/782 [==============================] - 4s 5ms/step - loss: 0.1903 - accuracy: 0.9259\n",
      "Epoch 17/30\n",
      "782/782 [==============================] - 4s 5ms/step - loss: 0.1726 - accuracy: 0.9322\n",
      "Epoch 18/30\n",
      "782/782 [==============================] - 4s 5ms/step - loss: 0.1677 - accuracy: 0.9372\n",
      "Epoch 19/30\n",
      "782/782 [==============================] - 4s 5ms/step - loss: 0.1549 - accuracy: 0.9397\n",
      "Epoch 20/30\n",
      "782/782 [==============================] - 4s 5ms/step - loss: 0.1448 - accuracy: 0.9454\n",
      "Epoch 21/30\n",
      "782/782 [==============================] - 4s 5ms/step - loss: 0.1291 - accuracy: 0.9519\n",
      "Epoch 22/30\n",
      "782/782 [==============================] - 4s 5ms/step - loss: 0.1460 - accuracy: 0.9458\n",
      "Epoch 23/30\n",
      "782/782 [==============================] - 4s 5ms/step - loss: 0.1188 - accuracy: 0.9572\n",
      "Epoch 24/30\n",
      "782/782 [==============================] - 4s 5ms/step - loss: 0.1292 - accuracy: 0.9570\n",
      "Epoch 25/30\n",
      "782/782 [==============================] - 4s 4ms/step - loss: 0.1095 - accuracy: 0.9618\n",
      "Epoch 26/30\n",
      "782/782 [==============================] - 5s 6ms/step - loss: 0.1107 - accuracy: 0.9627\n",
      "Epoch 27/30\n",
      "782/782 [==============================] - 6s 8ms/step - loss: 0.0935 - accuracy: 0.9704\n",
      "Epoch 28/30\n",
      "782/782 [==============================] - 5s 7ms/step - loss: 0.1107 - accuracy: 0.9675\n",
      "Epoch 29/30\n",
      "782/782 [==============================] - 5s 6ms/step - loss: 0.0733 - accuracy: 0.9780\n",
      "Epoch 30/30\n",
      "782/782 [==============================] - 4s 5ms/step - loss: 0.0828 - accuracy: 0.9761\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train, y_train, epochs=30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Y ahora veamos el rendimiento que obtenemos sobre el conjunto de pruebas, que no está mal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "782/782 [==============================] - 2s 3ms/step - loss: 0.3874 - accuracy: 0.8765\n",
      "Rendimiento en el conjunto de prueba: 0.877\n"
     ]
    }
   ],
   "source": [
    "lost, accuracy = model.evaluate(X_test, y_test)\n",
    "print(\"Rendimiento en el conjunto de prueba: {:.3f}\".format(accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parte 2: aplicación de redes neuronales a regresión (predicción del precio de la vivienda)\n",
    "\n",
    "Se pide aplicar un modelo de redes neuronales al problema de predecir precios de vivienda usando el conjunto de datos  `Boston house prices`. \n",
    "\n",
    "Hacerlo usando los dos sistemas vistos, comparando los resultados:\n",
    "* Scikit learn: usar `MLPRegressor`\n",
    "* Keras con Tensorflow: usar nuevamente `Sequential` y capas tipo `Dense` con la arquitectura adecuada.\n",
    "\n",
    "El conjunto de datos se puede cargar usando tanto scikit learn (`sklearn.datasets.load_boston`) como keras (`keras.datasets.boston_housing`). \n",
    "\n",
    "Como en la parte 1, se pide mostrar algunas pruebas de los resultados obtenidos usando distintas arquitecturas y/o hiperparámetros. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ejercicio\n",
    "Siguiendo la dinámica del ejercicio anterior, vamos a cargar el conjunto de datos `Boston house prices` y a continuación aplicar un modelo de redes neuronales utilizando Scikit learn y Keras.<br><br>Empecemos cargando los datos, para ello vamos a utilizar Keras mediante el método `load_data` que nos va a devolver dos tuplas de arrays: uno con el conjunto de entrenamiento y otro con el conjunto de prueba. Cada tupla tiene los datos (*X_train_code*, *X_test_code*), y su correspondiente clasificación (*y_train*, *y_test*) que son números entre 10 y 50 que representan el precio de la vivienda en miles de dólares."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(404, 13) (102, 13)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([  1.23247,   0.     ,   8.14   ,   0.     ,   0.538  ,   6.142  ,\n",
       "        91.7    ,   3.9769 ,   4.     , 307.     ,  21.     , 396.9    ,\n",
       "        18.72   ])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf \n",
    "from tensorflow import keras\n",
    "(X_train, y_train), (X_test, y_test) = keras.datasets.boston_housing.load_data()\n",
    "print(X_train.shape, X_test.shape)\n",
    "X_train[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Viendo los datos, antes de aplicar los modelos, es necesario normalizarlos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.01378163 0.         0.28152493 0.         0.31481481 0.49980635\n",
      " 0.91452111 0.29719123 0.13043478 0.22753346 0.89361702 1.\n",
      " 0.46881898]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "scaler = MinMaxScaler().fit(X_train)\n",
    "X_train = scaler.transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "print(X_train[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora que están normalizados, vamos a aplicar en primer lugar el sistema de scikit_learn `MLPRegressor` para hacer regresión. Vamos a ver el rendimiento que obtenemos con los valores por defecto (*alpha = 0.0001*)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rendimiento en entrenamiento: 0.712\n",
      "Rendimiento en el conjunto de prueba: 0.682\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neural_network import MLPRegressor\n",
    "mlpr = MLPRegressor(max_iter=1000, random_state=42)\n",
    "mlpr.fit(X_train, y_train)\n",
    "\n",
    "print(\"Rendimiento en entrenamiento: {:.3f}\".format(mlpr.score(X_train, y_train)))\n",
    "print(\"Rendimiento en el conjunto de prueba: {:.3f}\".format(mlpr.score(X_test, y_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Los rendimientos obtenidos en ambos conjuntos no son muy buenos. Probemos con distintos valores de *alpha* para ver si regularizando obtenemos mejores resultados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rendimiento en entrenamiento: 0.695\n",
      "Rendimiento en el conjunto de prueba: 0.676\n",
      "Rendimiento en entrenamiento: 0.713\n",
      "Rendimiento en el conjunto de prueba: 0.685\n"
     ]
    }
   ],
   "source": [
    "mlpr_1 = MLPRegressor(max_iter=1000, random_state=42, alpha = 1)\n",
    "mlpr_1.fit(X_train, y_train)\n",
    "print(\"Rendimiento en entrenamiento: {:.3f}\".format(mlpr_1.score(X_train, y_train)))\n",
    "print(\"Rendimiento en el conjunto de prueba: {:.3f}\".format(mlpr_1.score(X_test, y_test)))\n",
    "\n",
    "mlpr_05 = MLPRegressor(max_iter=1000, random_state=42, alpha = 0.005)\n",
    "mlpr_05.fit(X_train, y_train)\n",
    "print(\"Rendimiento en entrenamiento: {:.3f}\".format(mlpr_05.score(X_train, y_train)))\n",
    "print(\"Rendimiento en el conjunto de prueba: {:.3f}\".format(mlpr_05.score(X_test, y_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El rendimiento obtenido es prácticamente el mismo, mejora por milésimas con *alpha = 0.005*, en cambio con *alpha = 1* empeora.<br><br>Ahora vamos a aplicar *Keras* con Tensorflow usando el módulo `Sequential` y capas tipo `Dense`. Vamos a crear una red neuronal con la siguiente configuración:\n",
    "- Una capa inicial de tipo `Dense` con tantas entradas como número de características (13), con 100 unidades y función de activación ReLU.\n",
    "- Una capa intermedia de tipo `Dense`, con 100 unidades y función de activación ReLU.\n",
    "- Una última capa, la de salida, con 1 unidad y sin indicar función de activación, ya que por defecto es lineal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.Sequential()\n",
    "model.add(keras.layers.Dense(100, activation=\"relu\", input_shape=(X_train.shape[1],)))\n",
    "model.add(keras.layers.Dense(100, activation=\"relu\"))\n",
    "model.add(keras.layers.Dense(1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Especificamos la función de pérdida (`loss`), el optimizador (`optimizer`) para buscar los pesos adecuados y la métrica (`metrics`) para medir el rendimiento del modelo. En esta ocasión, al tratarse de un problema de regresión indicamos la función de pérdida error cuadrático medio (*mse, MeanSquaredError)*, como métrica error absoluto medio (*mae, MeanAbsoluteError*) y el optimizador *RMSprop*, que como se indica en la documentación: mantiene un promedio móvil (descontado) del cuadrado de gradientes y divide el gradiente por la raíz de este promedio."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss=\"mse\", optimizer=\"rmsprop\", metrics=[\"mae\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Entrenamos y evaluamos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 551.4251 - mae: 21.5651\n",
      "Epoch 2/30\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 444.4572 - mae: 18.8074\n",
      "Epoch 3/30\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 311.1948 - mae: 14.8081\n",
      "Epoch 4/30\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 195.4271 - mae: 10.9500\n",
      "Epoch 5/30\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 134.4777 - mae: 8.9187\n",
      "Epoch 6/30\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 110.5285 - mae: 8.0074\n",
      "Epoch 7/30\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 94.5248 - mae: 7.3276\n",
      "Epoch 8/30\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 80.7615 - mae: 6.6521\n",
      "Epoch 9/30\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 68.8009 - mae: 6.0808\n",
      "Epoch 10/30\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 60.2723 - mae: 5.5933\n",
      "Epoch 11/30\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 55.4319 - mae: 5.2124\n",
      "Epoch 12/30\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 51.3293 - mae: 5.0503\n",
      "Epoch 13/30\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 48.3395 - mae: 4.8997\n",
      "Epoch 14/30\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 45.6933 - mae: 4.6460\n",
      "Epoch 15/30\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 43.6277 - mae: 4.6207\n",
      "Epoch 16/30\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 42.0613 - mae: 4.5181\n",
      "Epoch 17/30\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 39.2207 - mae: 4.3727\n",
      "Epoch 18/30\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 36.7645 - mae: 4.2522\n",
      "Epoch 19/30\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 36.0698 - mae: 4.1389\n",
      "Epoch 20/30\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 33.5766 - mae: 4.0238\n",
      "Epoch 21/30\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 31.8924 - mae: 3.8506\n",
      "Epoch 22/30\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 30.1903 - mae: 3.8426\n",
      "Epoch 23/30\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 29.1491 - mae: 3.7236\n",
      "Epoch 24/30\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 27.2545 - mae: 3.5993\n",
      "Epoch 25/30\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 26.0512 - mae: 3.4854\n",
      "Epoch 26/30\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 25.1699 - mae: 3.4383\n",
      "Epoch 27/30\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 24.4409 - mae: 3.4198\n",
      "Epoch 28/30\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 23.3591 - mae: 3.2967\n",
      "Epoch 29/30\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 22.5562 - mae: 3.2692\n",
      "Epoch 30/30\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 22.2237 - mae: 3.1910\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 23.7276 - mae: 3.5453\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[23.727569580078125, 3.545335292816162]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "history = model.fit(X_train, y_train, epochs=30)\n",
    "model.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Viendo las estadísticas, en cada *epoch* se ha ido reduciendo la pérdida.<br><br>Veamos ahora la predicción de un ejemplo cualquiera y comprobamos si ha acertado."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valor de la predicción:  29.042421\n",
      "Valor real:  31.2\n"
     ]
    }
   ],
   "source": [
    "y_proba = model.predict(X_test[6:7])\n",
    "print(\"Valor de la predicción: \", y_proba[0][0])\n",
    "print(\"Valor real: \", y_test[6])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
